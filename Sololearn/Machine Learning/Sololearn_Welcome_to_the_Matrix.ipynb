{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac14429",
   "metadata": {},
   "source": [
    "# Sololearn: Welcome to the Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1af8d2",
   "metadata": {},
   "source": [
    "Calculating Evaluation Metrics using the Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a029842",
   "metadata": {},
   "source": [
    "## Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27c131",
   "metadata": {},
   "source": [
    "You will be given the values of the confusion matrix (true positives, false positives, false negatives, and true negatives). Your job is to compute the accuracy, precision, recall and f1 score and print the values rounded to 4 decimal places. To round you can use round(x, 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d20ec",
   "metadata": {},
   "source": [
    "**Input Format**\n",
    "\n",
    "The values of tp, fp, fn, tn, in that order separated by spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cc877",
   "metadata": {},
   "source": [
    "**Output Format**\n",
    "\n",
    "Each value on its own line, rounded to 4 decimal places, in this order: accuracy, precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ce30c",
   "metadata": {},
   "source": [
    "**Sample Input**\n",
    "\n",
    "`233 65 109 480`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f68665",
   "metadata": {},
   "source": [
    "**Sample Output**\n",
    "\n",
    "`0.8038\n",
    "0.7819\n",
    "0.6813\n",
    "0.7281`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc224dc0",
   "metadata": {},
   "source": [
    "The **Confusion Matrix** (or Error Matrix or Table of Confusion) is a table showing four values:\n",
    "- Datapoints we predicted positive that are actually positive (**tp**)\n",
    "- Datapoints we predicted positive that are actually negative (**fp**)\n",
    "- Datapoints we predicted negative that are actually positive (**fn**)\n",
    "- Datapoints we predicted negative that are actually negative (**tn**)\n",
    "\n",
    "The first and fourth are the datapoints we predicted correctly and the second and third are the datapoints we pedicted incorrectly. The four values of the Confusion Matrix are used to compute several different metrics that we'll use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630e2553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 65 109 480\n"
     ]
    }
   ],
   "source": [
    "tp, fp, fn, tn = [int(x) for x in input().split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083c130",
   "metadata": {},
   "source": [
    "**Accuracy** is the percent of predictions that are correct. Accuacy is a good measure if our classes are evenly split, but is very misleading if we have imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6272b",
   "metadata": {},
   "source": [
    "$$accuracy = \\frac{tp + tn}{tp + tn + fp + fn}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c1b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8045\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "print(round(accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656108a",
   "metadata": {},
   "source": [
    "**Precision** is the percent of the model's positive predictions that are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19698e0b",
   "metadata": {},
   "source": [
    "$$precision = \\frac{tp}{tp + fp}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bc35ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7841\n"
     ]
    }
   ],
   "source": [
    "precision = (tp)/(tp + fp)\n",
    "print(round(precision,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c85026",
   "metadata": {},
   "source": [
    "**Recall** is the percent of positive cases that the model predicts correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f89f1",
   "metadata": {},
   "source": [
    "$$recall = \\frac{tp}{tp + fn}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf5d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6841\n"
     ]
    }
   ],
   "source": [
    "recall = (tp)/(tp + fn)\n",
    "print(round(recall,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e2f50c",
   "metadata": {},
   "source": [
    "**F1 Score** is an average of precision and recall so that we have a single score for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26532af9",
   "metadata": {},
   "source": [
    "$$F1\\thinspace score = \\frac{2*precision*recall}{precision + recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a38b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7307\n"
     ]
    }
   ],
   "source": [
    "F1score = (2*precision*recall)/(precision + recall)\n",
    "print(round(F1score,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
